{
  "best_global_step": 1017,
  "best_metric": 0.4825392961502075,
  "best_model_checkpoint": "./models/tinyllama_reverse/checkpoint-1017",
  "epoch": 9.0,
  "eval_steps": 500,
  "global_step": 1017,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.08888888888888889,
      "grad_norm": 1.2349114418029785,
      "learning_rate": 1.984070796460177e-05,
      "loss": 2.2779,
      "step": 10
    },
    {
      "epoch": 0.17777777777777778,
      "grad_norm": 1.1958099603652954,
      "learning_rate": 1.9663716814159294e-05,
      "loss": 2.1552,
      "step": 20
    },
    {
      "epoch": 0.26666666666666666,
      "grad_norm": 1.2746188640594482,
      "learning_rate": 1.9486725663716816e-05,
      "loss": 2.0744,
      "step": 30
    },
    {
      "epoch": 0.35555555555555557,
      "grad_norm": 1.2498356103897095,
      "learning_rate": 1.9309734513274338e-05,
      "loss": 1.9661,
      "step": 40
    },
    {
      "epoch": 0.4444444444444444,
      "grad_norm": 1.392176628112793,
      "learning_rate": 1.913274336283186e-05,
      "loss": 1.8384,
      "step": 50
    },
    {
      "epoch": 0.5333333333333333,
      "grad_norm": 1.5180238485336304,
      "learning_rate": 1.8955752212389382e-05,
      "loss": 1.6836,
      "step": 60
    },
    {
      "epoch": 0.6222222222222222,
      "grad_norm": 1.6675060987472534,
      "learning_rate": 1.8778761061946905e-05,
      "loss": 1.5147,
      "step": 70
    },
    {
      "epoch": 0.7111111111111111,
      "grad_norm": 1.92742121219635,
      "learning_rate": 1.8601769911504427e-05,
      "loss": 1.346,
      "step": 80
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.5381275415420532,
      "learning_rate": 1.842477876106195e-05,
      "loss": 1.1949,
      "step": 90
    },
    {
      "epoch": 0.8888888888888888,
      "grad_norm": 1.2533098459243774,
      "learning_rate": 1.8247787610619468e-05,
      "loss": 1.0614,
      "step": 100
    },
    {
      "epoch": 0.9777777777777777,
      "grad_norm": 1.0593544244766235,
      "learning_rate": 1.8070796460176994e-05,
      "loss": 0.9719,
      "step": 110
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.9298341274261475,
      "eval_runtime": 361.1212,
      "eval_samples_per_second": 0.554,
      "eval_steps_per_second": 0.069,
      "step": 113
    },
    {
      "epoch": 1.0622222222222222,
      "grad_norm": 0.9796364903450012,
      "learning_rate": 1.7893805309734516e-05,
      "loss": 0.9054,
      "step": 120
    },
    {
      "epoch": 1.1511111111111112,
      "grad_norm": 1.195855736732483,
      "learning_rate": 1.7716814159292038e-05,
      "loss": 0.8698,
      "step": 130
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.7668701410293579,
      "learning_rate": 1.753982300884956e-05,
      "loss": 0.8444,
      "step": 140
    },
    {
      "epoch": 1.3288888888888888,
      "grad_norm": 0.8975256085395813,
      "learning_rate": 1.7362831858407083e-05,
      "loss": 0.8121,
      "step": 150
    },
    {
      "epoch": 1.4177777777777778,
      "grad_norm": 0.7528100609779358,
      "learning_rate": 1.71858407079646e-05,
      "loss": 0.7868,
      "step": 160
    },
    {
      "epoch": 1.5066666666666668,
      "grad_norm": 0.6765235662460327,
      "learning_rate": 1.7008849557522124e-05,
      "loss": 0.7802,
      "step": 170
    },
    {
      "epoch": 1.5955555555555554,
      "grad_norm": 0.9925315976142883,
      "learning_rate": 1.6831858407079646e-05,
      "loss": 0.7273,
      "step": 180
    },
    {
      "epoch": 1.6844444444444444,
      "grad_norm": 0.8977346420288086,
      "learning_rate": 1.665486725663717e-05,
      "loss": 0.7251,
      "step": 190
    },
    {
      "epoch": 1.7733333333333334,
      "grad_norm": 0.8877920508384705,
      "learning_rate": 1.6477876106194694e-05,
      "loss": 0.7214,
      "step": 200
    },
    {
      "epoch": 1.8622222222222222,
      "grad_norm": 0.8224477767944336,
      "learning_rate": 1.6300884955752213e-05,
      "loss": 0.6971,
      "step": 210
    },
    {
      "epoch": 1.951111111111111,
      "grad_norm": 0.8432276248931885,
      "learning_rate": 1.6123893805309735e-05,
      "loss": 0.7022,
      "step": 220
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.7018347382545471,
      "eval_runtime": 377.7928,
      "eval_samples_per_second": 0.529,
      "eval_steps_per_second": 0.066,
      "step": 226
    },
    {
      "epoch": 2.0355555555555553,
      "grad_norm": 1.1516846418380737,
      "learning_rate": 1.5946902654867257e-05,
      "loss": 0.6843,
      "step": 230
    },
    {
      "epoch": 2.1244444444444444,
      "grad_norm": 0.7566156983375549,
      "learning_rate": 1.576991150442478e-05,
      "loss": 0.678,
      "step": 240
    },
    {
      "epoch": 2.2133333333333334,
      "grad_norm": 0.8388705849647522,
      "learning_rate": 1.55929203539823e-05,
      "loss": 0.6676,
      "step": 250
    },
    {
      "epoch": 2.3022222222222224,
      "grad_norm": 1.0066006183624268,
      "learning_rate": 1.5415929203539824e-05,
      "loss": 0.6737,
      "step": 260
    },
    {
      "epoch": 2.391111111111111,
      "grad_norm": 0.6438790559768677,
      "learning_rate": 1.5238938053097348e-05,
      "loss": 0.6538,
      "step": 270
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.8998736143112183,
      "learning_rate": 1.506194690265487e-05,
      "loss": 0.6593,
      "step": 280
    },
    {
      "epoch": 2.568888888888889,
      "grad_norm": 0.9096846580505371,
      "learning_rate": 1.488495575221239e-05,
      "loss": 0.6619,
      "step": 290
    },
    {
      "epoch": 2.6577777777777776,
      "grad_norm": 0.9570869207382202,
      "learning_rate": 1.4707964601769913e-05,
      "loss": 0.658,
      "step": 300
    },
    {
      "epoch": 2.7466666666666666,
      "grad_norm": 0.9939981698989868,
      "learning_rate": 1.4530973451327435e-05,
      "loss": 0.6467,
      "step": 310
    },
    {
      "epoch": 2.8355555555555556,
      "grad_norm": 0.9596965909004211,
      "learning_rate": 1.4353982300884957e-05,
      "loss": 0.6501,
      "step": 320
    },
    {
      "epoch": 2.924444444444444,
      "grad_norm": 1.0232795476913452,
      "learning_rate": 1.417699115044248e-05,
      "loss": 0.6462,
      "step": 330
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.6368111371994019,
      "eval_runtime": 374.022,
      "eval_samples_per_second": 0.535,
      "eval_steps_per_second": 0.067,
      "step": 339
    },
    {
      "epoch": 3.008888888888889,
      "grad_norm": 0.7965937852859497,
      "learning_rate": 1.4e-05,
      "loss": 0.6231,
      "step": 340
    },
    {
      "epoch": 3.097777777777778,
      "grad_norm": 0.9207018613815308,
      "learning_rate": 1.3823008849557524e-05,
      "loss": 0.622,
      "step": 350
    },
    {
      "epoch": 3.1866666666666665,
      "grad_norm": 1.1957365274429321,
      "learning_rate": 1.3646017699115046e-05,
      "loss": 0.6157,
      "step": 360
    },
    {
      "epoch": 3.2755555555555556,
      "grad_norm": 1.0234483480453491,
      "learning_rate": 1.3469026548672568e-05,
      "loss": 0.6146,
      "step": 370
    },
    {
      "epoch": 3.3644444444444446,
      "grad_norm": 1.23129141330719,
      "learning_rate": 1.329203539823009e-05,
      "loss": 0.5915,
      "step": 380
    },
    {
      "epoch": 3.453333333333333,
      "grad_norm": 1.0701375007629395,
      "learning_rate": 1.3115044247787611e-05,
      "loss": 0.615,
      "step": 390
    },
    {
      "epoch": 3.542222222222222,
      "grad_norm": 1.022647500038147,
      "learning_rate": 1.2938053097345133e-05,
      "loss": 0.6012,
      "step": 400
    },
    {
      "epoch": 3.631111111111111,
      "grad_norm": 1.0162593126296997,
      "learning_rate": 1.2761061946902655e-05,
      "loss": 0.5969,
      "step": 410
    },
    {
      "epoch": 3.7199999999999998,
      "grad_norm": 1.1615197658538818,
      "learning_rate": 1.2584070796460178e-05,
      "loss": 0.5858,
      "step": 420
    },
    {
      "epoch": 3.8088888888888888,
      "grad_norm": 1.1126259565353394,
      "learning_rate": 1.2407079646017702e-05,
      "loss": 0.5921,
      "step": 430
    },
    {
      "epoch": 3.897777777777778,
      "grad_norm": 1.1731349229812622,
      "learning_rate": 1.2230088495575224e-05,
      "loss": 0.5713,
      "step": 440
    },
    {
      "epoch": 3.986666666666667,
      "grad_norm": 1.6270004510879517,
      "learning_rate": 1.2053097345132744e-05,
      "loss": 0.578,
      "step": 450
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.5835270881652832,
      "eval_runtime": 342.8262,
      "eval_samples_per_second": 0.583,
      "eval_steps_per_second": 0.073,
      "step": 452
    },
    {
      "epoch": 4.071111111111111,
      "grad_norm": 1.2485488653182983,
      "learning_rate": 1.1876106194690267e-05,
      "loss": 0.5587,
      "step": 460
    },
    {
      "epoch": 4.16,
      "grad_norm": 1.1626856327056885,
      "learning_rate": 1.1699115044247789e-05,
      "loss": 0.5765,
      "step": 470
    },
    {
      "epoch": 4.248888888888889,
      "grad_norm": 1.2335078716278076,
      "learning_rate": 1.1522123893805311e-05,
      "loss": 0.5598,
      "step": 480
    },
    {
      "epoch": 4.337777777777778,
      "grad_norm": 1.2465507984161377,
      "learning_rate": 1.1345132743362832e-05,
      "loss": 0.5693,
      "step": 490
    },
    {
      "epoch": 4.426666666666667,
      "grad_norm": 1.3244036436080933,
      "learning_rate": 1.1168141592920354e-05,
      "loss": 0.5573,
      "step": 500
    },
    {
      "epoch": 4.515555555555555,
      "grad_norm": 1.0505695343017578,
      "learning_rate": 1.0991150442477878e-05,
      "loss": 0.5541,
      "step": 510
    },
    {
      "epoch": 4.604444444444445,
      "grad_norm": 1.351513385772705,
      "learning_rate": 1.08141592920354e-05,
      "loss": 0.5452,
      "step": 520
    },
    {
      "epoch": 4.693333333333333,
      "grad_norm": 1.6747326850891113,
      "learning_rate": 1.0637168141592922e-05,
      "loss": 0.5473,
      "step": 530
    },
    {
      "epoch": 4.782222222222222,
      "grad_norm": 1.2953755855560303,
      "learning_rate": 1.0460176991150444e-05,
      "loss": 0.5524,
      "step": 540
    },
    {
      "epoch": 4.871111111111111,
      "grad_norm": 1.435482382774353,
      "learning_rate": 1.0283185840707965e-05,
      "loss": 0.5253,
      "step": 550
    },
    {
      "epoch": 4.96,
      "grad_norm": 1.4989196062088013,
      "learning_rate": 1.0106194690265487e-05,
      "loss": 0.5381,
      "step": 560
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.5420472025871277,
      "eval_runtime": 341.9409,
      "eval_samples_per_second": 0.585,
      "eval_steps_per_second": 0.073,
      "step": 565
    },
    {
      "epoch": 5.044444444444444,
      "grad_norm": 1.4545005559921265,
      "learning_rate": 9.92920353982301e-06,
      "loss": 0.5339,
      "step": 570
    },
    {
      "epoch": 5.133333333333334,
      "grad_norm": 1.3979682922363281,
      "learning_rate": 9.752212389380532e-06,
      "loss": 0.5241,
      "step": 580
    },
    {
      "epoch": 5.222222222222222,
      "grad_norm": 1.1472004652023315,
      "learning_rate": 9.575221238938054e-06,
      "loss": 0.5193,
      "step": 590
    },
    {
      "epoch": 5.311111111111111,
      "grad_norm": 1.4329869747161865,
      "learning_rate": 9.398230088495576e-06,
      "loss": 0.5179,
      "step": 600
    },
    {
      "epoch": 5.4,
      "grad_norm": 1.1576604843139648,
      "learning_rate": 9.221238938053098e-06,
      "loss": 0.5152,
      "step": 610
    },
    {
      "epoch": 5.488888888888889,
      "grad_norm": 1.3737239837646484,
      "learning_rate": 9.04424778761062e-06,
      "loss": 0.5093,
      "step": 620
    },
    {
      "epoch": 5.5777777777777775,
      "grad_norm": 1.1941062211990356,
      "learning_rate": 8.867256637168143e-06,
      "loss": 0.5171,
      "step": 630
    },
    {
      "epoch": 5.666666666666667,
      "grad_norm": 1.6354312896728516,
      "learning_rate": 8.690265486725665e-06,
      "loss": 0.5167,
      "step": 640
    },
    {
      "epoch": 5.7555555555555555,
      "grad_norm": 1.4153265953063965,
      "learning_rate": 8.513274336283186e-06,
      "loss": 0.5224,
      "step": 650
    },
    {
      "epoch": 5.844444444444444,
      "grad_norm": 1.3255516290664673,
      "learning_rate": 8.33628318584071e-06,
      "loss": 0.5126,
      "step": 660
    },
    {
      "epoch": 5.933333333333334,
      "grad_norm": 1.5985360145568848,
      "learning_rate": 8.15929203539823e-06,
      "loss": 0.5199,
      "step": 670
    },
    {
      "epoch": 6.0,
      "eval_loss": 0.5141294002532959,
      "eval_runtime": 289.808,
      "eval_samples_per_second": 0.69,
      "eval_steps_per_second": 0.086,
      "step": 678
    },
    {
      "epoch": 6.017777777777778,
      "grad_norm": 1.2760804891586304,
      "learning_rate": 7.982300884955752e-06,
      "loss": 0.5119,
      "step": 680
    },
    {
      "epoch": 6.1066666666666665,
      "grad_norm": 1.1159448623657227,
      "learning_rate": 7.805309734513274e-06,
      "loss": 0.4937,
      "step": 690
    },
    {
      "epoch": 6.195555555555556,
      "grad_norm": 1.612869143486023,
      "learning_rate": 7.6283185840707975e-06,
      "loss": 0.4932,
      "step": 700
    },
    {
      "epoch": 6.2844444444444445,
      "grad_norm": 1.2466495037078857,
      "learning_rate": 7.451327433628319e-06,
      "loss": 0.5065,
      "step": 710
    },
    {
      "epoch": 6.373333333333333,
      "grad_norm": 1.333544373512268,
      "learning_rate": 7.274336283185841e-06,
      "loss": 0.5085,
      "step": 720
    },
    {
      "epoch": 6.4622222222222225,
      "grad_norm": 1.626842975616455,
      "learning_rate": 7.0973451327433625e-06,
      "loss": 0.4958,
      "step": 730
    },
    {
      "epoch": 6.551111111111111,
      "grad_norm": 1.4445314407348633,
      "learning_rate": 6.9203539823008856e-06,
      "loss": 0.5019,
      "step": 740
    },
    {
      "epoch": 6.64,
      "grad_norm": 1.1728404760360718,
      "learning_rate": 6.743362831858408e-06,
      "loss": 0.4885,
      "step": 750
    },
    {
      "epoch": 6.728888888888889,
      "grad_norm": 1.3093047142028809,
      "learning_rate": 6.566371681415929e-06,
      "loss": 0.4964,
      "step": 760
    },
    {
      "epoch": 6.817777777777778,
      "grad_norm": 1.5872796773910522,
      "learning_rate": 6.389380530973451e-06,
      "loss": 0.4963,
      "step": 770
    },
    {
      "epoch": 6.906666666666666,
      "grad_norm": 1.4049289226531982,
      "learning_rate": 6.2123893805309745e-06,
      "loss": 0.5056,
      "step": 780
    },
    {
      "epoch": 6.995555555555556,
      "grad_norm": 1.310065507888794,
      "learning_rate": 6.035398230088496e-06,
      "loss": 0.4784,
      "step": 790
    },
    {
      "epoch": 7.0,
      "eval_loss": 0.49763190746307373,
      "eval_runtime": 334.0032,
      "eval_samples_per_second": 0.599,
      "eval_steps_per_second": 0.075,
      "step": 791
    },
    {
      "epoch": 7.08,
      "grad_norm": 1.34581458568573,
      "learning_rate": 5.858407079646018e-06,
      "loss": 0.4848,
      "step": 800
    },
    {
      "epoch": 7.168888888888889,
      "grad_norm": 1.4014506340026855,
      "learning_rate": 5.6814159292035395e-06,
      "loss": 0.4792,
      "step": 810
    },
    {
      "epoch": 7.257777777777778,
      "grad_norm": 1.593582272529602,
      "learning_rate": 5.5044247787610626e-06,
      "loss": 0.4815,
      "step": 820
    },
    {
      "epoch": 7.346666666666667,
      "grad_norm": 1.4123793840408325,
      "learning_rate": 5.327433628318585e-06,
      "loss": 0.4886,
      "step": 830
    },
    {
      "epoch": 7.435555555555555,
      "grad_norm": 1.3968663215637207,
      "learning_rate": 5.150442477876106e-06,
      "loss": 0.4849,
      "step": 840
    },
    {
      "epoch": 7.524444444444445,
      "grad_norm": 1.9936397075653076,
      "learning_rate": 4.973451327433628e-06,
      "loss": 0.4894,
      "step": 850
    },
    {
      "epoch": 7.613333333333333,
      "grad_norm": 1.535513997077942,
      "learning_rate": 4.796460176991151e-06,
      "loss": 0.4816,
      "step": 860
    },
    {
      "epoch": 7.702222222222222,
      "grad_norm": 1.6084575653076172,
      "learning_rate": 4.619469026548673e-06,
      "loss": 0.4861,
      "step": 870
    },
    {
      "epoch": 7.791111111111111,
      "grad_norm": 1.6770859956741333,
      "learning_rate": 4.442477876106195e-06,
      "loss": 0.4718,
      "step": 880
    },
    {
      "epoch": 7.88,
      "grad_norm": 1.6241945028305054,
      "learning_rate": 4.265486725663717e-06,
      "loss": 0.4806,
      "step": 890
    },
    {
      "epoch": 7.968888888888889,
      "grad_norm": 1.211535930633545,
      "learning_rate": 4.088495575221239e-06,
      "loss": 0.4799,
      "step": 900
    },
    {
      "epoch": 8.0,
      "eval_loss": 0.48751163482666016,
      "eval_runtime": 321.7048,
      "eval_samples_per_second": 0.622,
      "eval_steps_per_second": 0.078,
      "step": 904
    },
    {
      "epoch": 8.053333333333333,
      "grad_norm": 1.422712802886963,
      "learning_rate": 3.911504424778762e-06,
      "loss": 0.4821,
      "step": 910
    },
    {
      "epoch": 8.142222222222221,
      "grad_norm": 1.2918221950531006,
      "learning_rate": 3.734513274336283e-06,
      "loss": 0.4882,
      "step": 920
    },
    {
      "epoch": 8.231111111111112,
      "grad_norm": 1.3157132863998413,
      "learning_rate": 3.557522123893806e-06,
      "loss": 0.4797,
      "step": 930
    },
    {
      "epoch": 8.32,
      "grad_norm": 1.9053927659988403,
      "learning_rate": 3.3805309734513276e-06,
      "loss": 0.4811,
      "step": 940
    },
    {
      "epoch": 8.408888888888889,
      "grad_norm": 1.38556969165802,
      "learning_rate": 3.20353982300885e-06,
      "loss": 0.4762,
      "step": 950
    },
    {
      "epoch": 8.497777777777777,
      "grad_norm": 1.4716862440109253,
      "learning_rate": 3.0265486725663717e-06,
      "loss": 0.4717,
      "step": 960
    },
    {
      "epoch": 8.586666666666666,
      "grad_norm": 1.6009316444396973,
      "learning_rate": 2.8495575221238943e-06,
      "loss": 0.4801,
      "step": 970
    },
    {
      "epoch": 8.675555555555556,
      "grad_norm": 1.6013879776000977,
      "learning_rate": 2.672566371681416e-06,
      "loss": 0.4755,
      "step": 980
    },
    {
      "epoch": 8.764444444444445,
      "grad_norm": 1.5677151679992676,
      "learning_rate": 2.4955752212389383e-06,
      "loss": 0.4666,
      "step": 990
    },
    {
      "epoch": 8.853333333333333,
      "grad_norm": 1.3299206495285034,
      "learning_rate": 2.3185840707964606e-06,
      "loss": 0.4751,
      "step": 1000
    },
    {
      "epoch": 8.942222222222222,
      "grad_norm": 1.8519997596740723,
      "learning_rate": 2.1415929203539824e-06,
      "loss": 0.4736,
      "step": 1010
    },
    {
      "epoch": 9.0,
      "eval_loss": 0.4825392961502075,
      "eval_runtime": 331.0651,
      "eval_samples_per_second": 0.604,
      "eval_steps_per_second": 0.076,
      "step": 1017
    }
  ],
  "logging_steps": 10,
  "max_steps": 1130,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 5.17081845989376e+16,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
